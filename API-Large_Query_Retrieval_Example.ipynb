{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://geoscience.data.qld.gov.au/api/action/package_search?q=seismic&rows=1000&start=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the API endpoint\n",
    "api = 'https://geoscience.data.qld.gov.au/api/action/'\n",
    "# construct our query\n",
    "query = api + 'package_search?q=seismic&rows=1000'\n",
    "# make the get request and store it in the response object\n",
    "response = requests.get(query)\n",
    "# view the payload as JSON\n",
    "json_response = response.json()\n",
    "\n",
    "#and get a count of results we can retrieve\n",
    "total_results = json_response['result']['count']\n",
    "\n",
    "#hack without understanding/researching the api too much\n",
    "getloop = int(total_results/1000) + 1\n",
    "\n",
    "results_list = []\n",
    "for i in range(getloop):\n",
    "    loopq = query + \"&start=\" + str(i*1000)\n",
    "    response = requests.get(loopq)\n",
    "    json_response = response.json()\n",
    "    \n",
    "    results_list.append(json_response)\n",
    "\n",
    "# print the GeoJSON for the results\n",
    "#for index, dataset in enumerate(json_response['result']['results']):\n",
    "    #print(dataset.get('GeoJSONextent'))\n",
    "    #print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at a result for the structure\n",
    "results_list[0]['result']['results'][887]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each one has organisation - don't really need\n",
    "#id, , author, spatial, type is useful\n",
    "#resources - a list of dicts, \n",
    "#eg resource:description:\n",
    "#resource description dictionary\n",
    "#a resource id, resource:size, resource:, download_url, name, url, resource_type etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will try and make a dataframe\n",
    "#but using the batched results, getting the ids\n",
    "#turning the resource dictionaries into dataframes, concatenating\n",
    "#then concatenating back at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ids = []\n",
    "for batch in tqdm(results_list, total=len(results_list) ):\n",
    "    results = batch['result']['results']\n",
    "    for r in results:\n",
    "        rid = r['id']\n",
    "        rauthor = r['author']\n",
    "        rspatial = r['spatial']\n",
    "        rtype = r['type']\n",
    "        \n",
    "        if len(r['resources']) > 0:\n",
    "            part_list = []\n",
    "            for part in r['resources']:\n",
    "                #df = pd.DataFrame.from_dict(part)\n",
    "                df = pd.DataFrame([part])\n",
    "                df['rid'] = rid\n",
    "                df['rauthor'] = rauthor\n",
    "                df['rspatial'] = rspatial\n",
    "                df['type'] = rtype\n",
    "                part_list.append(df)\n",
    "                allparts = pd.concat(part_list)\n",
    "                \n",
    "            result_ids.append(allparts)\n",
    "\n",
    "dfDatasets = pd.concat(result_ids)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDatasets.to_csv(r'H:\\GSQ_Seimisc_Datasets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "4267\n",
      "aaa7c8c3-d69b-4ae6-bc4b-2542301b7e6e\n",
      "39bc2c60-d727-4383-b82d-6af7fdf8cf7b\n",
      "2f3d761c-6506-438a-934a-87e48cc8d25e\n",
      "8a1f58c4-2e61-44a5-a573-794396652ea6\n",
      "55a1c3a1-107f-4a65-9bec-bef9e6eb8d6b\n",
      "8157408f-83af-4515-9279-f502ae16c155\n",
      "37a2fb0c-49c5-444a-a7da-4947ae9dad94\n",
      "3897db72-0d38-4f11-aad4-8fa8907d20bb\n",
      "4d5ae331-3cfb-4042-a4b5-1955c135cace\n",
      "30b6b5fc-ba25-4bfe-a76b-c35d72ba07e0\n"
     ]
    }
   ],
   "source": [
    "#this is what a default query would look like\n",
    "query_default = api + 'package_search?q=seismic\n",
    "\n",
    "response = requests.get(query_default)\n",
    "json_response = response.json()\n",
    "\n",
    "print(json_response['result']['count'])\n",
    "print(len(json_response['result']['results']) )\n",
    "for x in json_response['result']['results']:\n",
    "    print(x[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many are of type seismic, not report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfDatasets.loc[dfDatasets['type'] == 'seismic']['rid'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gempy2021]",
   "language": "python",
   "name": "conda-env-gempy2021-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
